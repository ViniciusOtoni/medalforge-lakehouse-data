bundle:
  name: one-data-bronze
  databricks_cli_version: ">=0.220.0"

variables:
  dynamic_spn_client_id:
    description: "Client ID da SPN dinÃ¢mica para run_as e permissions"
  cluster_spark_version:
    description: "DBR LTS do job cluster"
    default: "14.3.x-scala2.12"
  node_type_id:
    description: "SKU do node do job cluster"
    default: "Standard_F4"

# run_as pode continuar usando var (vamos injetar por env DATABRICKS_BUNDLE_VAR_dynamic_spn_client_id)
run_as:
  service_principal_name: ${var.dynamic_spn_client_id}

targets:
  dev:
    default: true
    sync:
      include:
        - bronze/**
      exclude:
        - .git/**
        - .github/**
        - .assets/
        - .data/

    resources:
      jobs:
        ingest_bronze:
          name: one-data-bronze-ingest
          permissions:
            - level: CAN_MANAGE
              service_principal_name: ${var.dynamic_spn_client_id}
          tasks:
            - task_key: ingest
              spark_python_task:
                python_file: ./bronze/main.py
                parameters:
                  - --mode
                  - validate+plan+ingest
                  - --contract_path
                  - ./bronze/contracts/dummy.json
              job_cluster_key: jc_small
              libraries:
                - pypi:
                    package: "pydantic>=2,<3"

          job_clusters:
            - job_cluster_key: jc_small
              new_cluster:
                spark_version: ${var.cluster_spark_version}
                node_type_id: ${var.node_type_id}
                num_workers: 1
                data_security_mode: SINGLE_USER
                custom_tags:
                  project: one-data
                  layer: bronze
                  purpose: ingest
